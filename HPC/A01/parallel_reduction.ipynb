{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "parallel_reduction.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM159GPpvEC1M6/0krZSqLL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HeptaDecane/LP1_SEM7/blob/main/HPC/A01/parallel_reduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3haYU616kqw",
        "outputId": "a0cb861c-ccde-41b6-e431-df27090de951",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S1V0s1L7i_l"
      },
      "source": [
        "code = \"\"\"\n",
        "#include<iostream>\n",
        "#include<math.h>\n",
        "\n",
        "#define n 8\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__global__ void minimum(int *input) {\n",
        "    int tid = threadIdx.x;\n",
        "    int step_size = 1;\n",
        "    int number_of_threads = blockDim.x;\n",
        "\n",
        "    printf(\"No of threads = %d\", number_of_threads);\n",
        "\n",
        "    while(number_of_threads>0) {\n",
        "        if(tid < number_of_threads) {\n",
        "            int first = tid*step_size*2;\n",
        "            int second = first + step_size;\n",
        "            if(input[second] < input[first])\n",
        "                input[first] = input[second];\n",
        "        }\n",
        "        step_size <<= 1;\n",
        "        number_of_threads >>= 1;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void maximum(int *input) {\n",
        "    int tid = threadIdx.x;\n",
        "    int step_size = 1;\n",
        "    int number_of_threads = blockDim.x;\n",
        "\n",
        "    while(number_of_threads>0) {\n",
        "        if(tid < number_of_threads) {\n",
        "            int first = tid*step_size*2;\n",
        "            int second = first + step_size;\n",
        "            if(input[second] > input[first])\n",
        "                input[first] = input[second];\n",
        "        }\n",
        "        step_size <<= 1;\n",
        "        number_of_threads >>= 1;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void sum(int *input) {\n",
        "    const int tid = threadIdx.x;\n",
        "    int step_size = 1;\n",
        "    int number_of_threads = blockDim.x;\n",
        "\n",
        "    while(number_of_threads > 0) {\n",
        "        if(tid < number_of_threads) {\n",
        "            int first = tid * step_size * 2;\n",
        "            int second = first + step_size;\n",
        "\n",
        "            input[first] += input[second];\n",
        "        }\n",
        "        step_size <<= 1;\n",
        "        number_of_threads >>= 1;\n",
        "\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void mean_diff_sq(float *input, float mean) {\n",
        "    input[threadIdx.x] -= mean;\n",
        "    input[threadIdx.x] *= input[threadIdx.x];\n",
        "}\n",
        "\n",
        "__global__ void sum_floats(float *input) {\n",
        "    int tid = threadIdx.x;\n",
        "    int step_size = 1;\n",
        "    int number_of_threads = blockDim.x;\n",
        "\n",
        "    while(number_of_threads > 0) {\n",
        "        if(tid < number_of_threads) {\n",
        "            int first = tid * step_size * 2;\n",
        "            int second = first + step_size;\n",
        "\n",
        "            input[first] += input[second];\n",
        "        }\n",
        "        step_size <<= 1;\n",
        "        number_of_threads >>= 1;\n",
        "\n",
        "    }\n",
        "}\n",
        "\n",
        "void copy_int_to_float(float *dest, int *src, int size){\n",
        "    for(int i=0; i<size; i++)\n",
        "        dest[i] = float(src[i]);\n",
        "}\n",
        "\n",
        "void random_ints(int *input, int size) {\n",
        "    cout<<\"Input: \";\n",
        "    for(int i=0; i<size; i++)  {\n",
        "        input[i] = rand()%100;\n",
        "        cout<<input[i]<<\"  \";\n",
        "    }\n",
        "    cout<<endl;\n",
        "\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    //int n=8;\n",
        "    int size = n*sizeof(int); //calculate no. of bytes for array\n",
        "\n",
        "    int *arr;\n",
        "    int *arr_d, result;\n",
        "\n",
        "    arr = (int *)malloc(size);\n",
        "    random_ints(arr, n);\n",
        "\n",
        "    cudaMalloc((void **)&arr_d, size);\n",
        "\n",
        "    //MIN\n",
        "    cudaMemcpy(arr_d, arr, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    minimum<<<1,n/2>>>(arr_d);\n",
        "\n",
        "    cudaMemcpy(&result, arr_d, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cout<<\"The minimum element is \"<<result<<endl;\n",
        "\n",
        "\n",
        "    //MAX\n",
        "    cudaMemcpy(arr_d, arr, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    maximum<<<1,n/2>>>(arr_d);\n",
        "\n",
        "    cudaMemcpy(&result, arr_d, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cout<<\"The maximum element is \"<<result<<endl;\n",
        "\n",
        "    //SUM\n",
        "    cudaMemcpy(arr_d, arr, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    sum<<<1,n/2>>>(arr_d);\n",
        "\n",
        "    cudaMemcpy(&result, arr_d, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cout<<\"The sum is \"<<result<<endl;\n",
        "\n",
        "    //AVERAGE\n",
        "\n",
        "    float mean = float(result)/n;\n",
        "    cout<<\"The mean is \"<<mean<<endl;\n",
        "\n",
        "    //STANDARD DEVIATION\n",
        "    float *arr_float;\n",
        "    float *arr_std, stdValue;\n",
        "\n",
        "    arr_float = (float *)malloc(n*sizeof(float));\n",
        "    cudaMalloc((void **)&arr_std, n*sizeof(float));\n",
        "\n",
        "    copy_int_to_float(arr_float, arr, n);\n",
        "\n",
        "    cudaMemcpy(arr_std, arr_float, n*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    mean_diff_sq <<<1,n>>>(arr_std, mean);\n",
        "    sum_floats<<<1,n/2>>>(arr_std);\n",
        "\n",
        "    cudaMemcpy(&stdValue, arr_std, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "\n",
        "    stdValue = stdValue / n;\n",
        "    cout<<\"The variance is \"<<stdValue<<endl;\n",
        "    stdValue = sqrt(stdValue);\n",
        "\n",
        "    cout<<\"The standard deviation is \"<<stdValue<<endl;\n",
        "\n",
        "    cudaFree(arr_d);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\"\"\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v5uA6bx8BNY"
      },
      "source": [
        "file = open(\"parallel_reduction.cu\", \"w\")\n",
        "file.write(code)\n",
        "file.close()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuCoEAcY8Ucr"
      },
      "source": [
        "!nvcc parallel_reduction.cu"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBaPZ_oZ8eQd",
        "outputId": "6d994540-6b33-433a-9d2c-6954f209a434",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!./a.out"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: 83  86  77  15  93  35  86  92  \n",
            "The minimum element is 83\n",
            "The maximum element is 83\n",
            "The sum is 83\n",
            "The mean is 10.375\n",
            "The variance is 10.375\n",
            "The standard deviation is 3.22102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ApGj54P8sGU",
        "outputId": "73314de0-f3de-41d2-8e2d-d68fbefe6452",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvprof ./a.out"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: 83  86  77  15  93  35  86  92  \n",
            "==453== NVPROF is profiling process 453, command: ./a.out\n",
            "==453== Warning: Auto boost enabled on device 0. Profiling results may be inconsistent.\n",
            "The minimum element is 83\n",
            "The maximum element is 83\n",
            "The sum is 83\n",
            "The mean is 10.375\n",
            "The variance is 10.375\n",
            "The standard deviation is 3.22102\n",
            "==453== Profiling application: ./a.out\n",
            "==453== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   56.20%  8.9920us         4  2.2480us  2.0800us  2.4000us  [CUDA memcpy DtoH]\n",
            "                   43.80%  7.0080us         4  1.7520us  1.5680us  2.3040us  [CUDA memcpy HtoD]\n",
            "      API calls:   99.38%  178.78ms         2  89.391ms  10.057us  178.77ms  cudaMalloc\n",
            "                    0.36%  646.97us         1  646.97us  646.97us  646.97us  cuDeviceTotalMem\n",
            "                    0.13%  239.77us       101  2.3730us     159ns  115.79us  cuDeviceGetAttribute\n",
            "                    0.09%  164.80us         8  20.599us  10.650us  36.186us  cudaMemcpy\n",
            "                    0.02%  29.499us         1  29.499us  29.499us  29.499us  cuDeviceGetName\n",
            "                    0.01%  12.322us         1  12.322us  12.322us  12.322us  cudaFree\n",
            "                    0.00%  4.8220us         1  4.8220us  4.8220us  4.8220us  cuDeviceGetPCIBusId\n",
            "                    0.00%  3.5430us         5     708ns     431ns  1.1620us  cudaLaunchKernel\n",
            "                    0.00%  2.1990us         3     733ns     212ns  1.0600us  cuDeviceGetCount\n",
            "                    0.00%  1.9620us         2     981ns     441ns  1.5210us  cuDeviceGet\n",
            "                    0.00%     448ns         1     448ns     448ns     448ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    }
  ]
}